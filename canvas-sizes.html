<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Canvas Sizer</title>
    <style>
        #controls {
            margin-bottom: 10px;
        }

        button,
        select,
        input {
            margin: 5px;
        }
    </style>
</head>

<body>

    <div id="controls">
        <label for="context">Context:</label>
        <select id="context">
            <option value="">Unset</option>
            <option value="2d">2D</option>
            <option value="webgl">WebGL</option>
            <option value="webgl2">WebGL 2</option>
            <option id="webgpu" value="webgpu">WebGPU</option>
        </select>

        <label>Width:</label>
        <input type="number" id="w" min="-1">

        <label>Height:</label>
        <input type="number" id="h" min="-1">

        <button onclick="resize()">Resize</button>
    </div>

    <div id="canvas_container" style="resize: both; overflow: hidden; background-color: aqua;">
        <canvas id="canvas"></canvas>
    </div>

    <div>
        <button onclick="draw()">Draw</button>
        <button onclick="toDataURL()">toDataURL</button>
        <button onclick="toBlob()">toBlob</button>
        <button onclick="createBitmap()">createImageBitmap</button>
    </div>

    <script type="module">
        const canvas_container = document.getElementById("canvas_container");
        let canvas = document.getElementById("canvas");
        const context_selector = document.getElementById("context");
        context_selector.addEventListener('input', async (e) => {
            await recreate_context();
        });
        const w = document.getElementById("w");
        const h = document.getElementById("h");
        let context;
        let webgpu_device;

        if (!navigator.gpu) {
            document.getElementById("webgpu").hidden = true;
        } else {
            const webgpu_adapter = await navigator.gpu.requestAdapter();
            webgpu_device = await webgpu_adapter.requestDevice();
        }

        async function recreate_context() {
            // recreate canvas
            const temp = canvas.cloneNode(true);
            canvas.replaceWith(temp);
            canvas = temp;
            // create context
            context = canvas.getContext(context_selector.value);
            if (context_selector.value == "webgpu") {
                context.configure({
                    device: webgpu_device,
                    format: navigator.gpu.getPreferredCanvasFormat(),
                    alphaMode: 'premultiplied'
                });
            }
        }

        window.resize = (width, height) => {
            w.value = width;
            h.value = height;
            canvas_container.style.width = `${w.value}px`;
            canvas_container.style.height = `${h.value}px`;
            canvas.width = width;
            canvas.height = height;
        }

        const resizeObserver = new ResizeObserver((entries) => {
            requestAnimationFrame(() => {
                for (const entry of entries) {
                    const { width, height } = entry.contentRect;
                    resize(Math.round(width), Math.round(height));
                }
            });
        });

        resizeObserver.observe(canvas_container);

        resize(600, 400);
        await recreate_context();

        window.draw = () => {
            switch (context_selector.value) {
                case "2d":
                    draw2D();
                    break;
                case "webgl":
                case "webgl2":
                    drawWebGL();
                    break;
                case "webgpu":
                    drawWebGPU();
                    break;
                case "unset":
                    console.warn("Context is unset");
                    break;
            }
        }

        function draw2D() {
            const ctx = context;
            var v1 = { x: canvas.width * 0.1, y: canvas.height * 0.9 };
            var v2 = { x: canvas.width * 0.9, y: canvas.height * 0.9 };
            var v3 = { x: canvas.width * 0.5, y: canvas.height * 0.1 };

            var radius = Math.max(canvas.width * 0.5, canvas.height * 0.8);

            var grd1 = ctx.createRadialGradient(v1.x, v1.y, 0, v1.x, v1.y, radius);
            grd1.addColorStop(0, "#FF0000FF");
            grd1.addColorStop(1, "#FF000000");

            var grd2 = ctx.createRadialGradient(v2.x, v2.y, 0, v2.x, v2.y, radius);
            grd2.addColorStop(0, "#00FF00FF");
            grd2.addColorStop(1, "#00FF0000");

            var grd3 = ctx.createRadialGradient(v3.x, v3.y, 0, v3.x, v3.y, radius);
            grd3.addColorStop(0, "#0000FFFF");
            grd3.addColorStop(1, "#0000FF00");

            ctx.beginPath();

            ctx.moveTo(v1.x, v1.y);
            ctx.lineTo(v2.x, v2.y);
            ctx.lineTo(v3.x, v3.y);

            ctx.closePath();

            // fill with black
            ctx.fill();

            // set blend mode
            ctx.globalCompositeOperation = "lighter";

            ctx.fillStyle = grd1;
            ctx.fill();

            ctx.fillStyle = grd2;
            ctx.fill();

            ctx.fillStyle = grd3;
            ctx.fill();

            ctx.globalCompositeOperation = "destination-atop";
            ctx.fillStyle = "rgb(0 50% 100%)"
            ctx.fillRect(0, 0, canvas.width, canvas.height);
        }

        function drawWebGL() {
            const gl = context;
            gl.viewport(0, 0, canvas.width, canvas.height);
            gl.clearColor(0, 0.5, 1.0, 1.0);
            gl.clear(gl.COLOR_BUFFER_BIT);

            const vertexShaderSource = `
        attribute vec2 position;
        attribute vec3 color;
        varying vec3 vColor;
        void main() {
          gl_Position = vec4(position, 0.0, 1.0);
          vColor = color;
        }`;
            const fragmentShaderSource = `
        precision mediump float;
        varying vec3 vColor;
        void main() {
          gl_FragColor = vec4(vColor, 1.0);
        }`;

            const vs = gl.createShader(gl.VERTEX_SHADER);
            gl.shaderSource(vs, vertexShaderSource);
            gl.compileShader(vs);

            const fs = gl.createShader(gl.FRAGMENT_SHADER);
            gl.shaderSource(fs, fragmentShaderSource);
            gl.compileShader(fs);

            const program = gl.createProgram();
            gl.attachShader(program, vs);
            gl.attachShader(program, fs);
            gl.linkProgram(program);
            gl.useProgram(program);

            const vertices = new Float32Array([
                0.0, 0.8, 1, 0, 0,
                -0.8, -0.8, 0, 1, 0,
                0.8, -0.8, 0, 0, 1,
            ]);

            const buffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
            gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);

            const position = gl.getAttribLocation(program, "position");
            gl.enableVertexAttribArray(position);
            gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 20, 0);

            const color = gl.getAttribLocation(program, "color");
            gl.enableVertexAttribArray(color);
            gl.vertexAttribPointer(color, 3, gl.FLOAT, false, 20, 8);

            gl.drawArrays(gl.TRIANGLES, 0, 3);
        }

        async function drawWebGPU() {
            const device = webgpu_device;

            // Clear color for GPURenderPassDescriptor
            const clearColor = { r: 0.0, g: 0.5, b: 1.0, a: 1.0 };

            // Vertex data for triangle
            // Each vertex has 8 values representing position and color: X Y Z W R G B A

            const vertices = new Float32Array([
                0.0, 0.8, 0, 1, 1, 0, 0, 1,
                -0.8, -0.8, 0, 1, 0, 1, 0, 1,
                0.8, -0.8, 0, 1, 0, 0, 1, 1
            ]);

            // Vertex and fragment shaders

            const shaders = `
struct VertexOut {
@builtin(position) position : vec4f,
@location(0) color : vec4f
}

@vertex
fn vertex_main(@location(0) position: vec4f,
           @location(1) color: vec4f) -> VertexOut
{
var output : VertexOut;
output.position = position;
output.color = color;
return output;
}

@fragment
fn fragment_main(fragData: VertexOut) -> @location(0) vec4f
{
return fragData.color;
}
`;

            // 2: Create a shader module from the shaders template literal
            const shaderModule = device.createShaderModule({
                code: shaders
            });

            // 4: Create vertex buffer to contain vertex data
            const vertexBuffer = device.createBuffer({
                size: vertices.byteLength, // make it big enough to store vertices in
                usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
            });

            // Copy the vertex data over to the GPUBuffer using the writeBuffer() utility function
            device.queue.writeBuffer(vertexBuffer, 0, vertices, 0, vertices.length);

            // 5: Create a GPUVertexBufferLayout and GPURenderPipelineDescriptor to provide a definition of our render pipline
            const vertexBuffers = [{
                attributes: [{
                    shaderLocation: 0, // position
                    offset: 0,
                    format: 'float32x4'
                }, {
                    shaderLocation: 1, // color
                    offset: 16,
                    format: 'float32x4'
                }],
                arrayStride: 32,
                stepMode: 'vertex'
            }];

            const pipelineDescriptor = {
                vertex: {
                    module: shaderModule,
                    entryPoint: 'vertex_main',
                    buffers: vertexBuffers
                },
                fragment: {
                    module: shaderModule,
                    entryPoint: 'fragment_main',
                    targets: [{
                        format: navigator.gpu.getPreferredCanvasFormat()
                    }]
                },
                primitive: {
                    topology: 'triangle-list'
                },
                layout: 'auto'
            };

            // 6: Create the actual render pipeline

            const renderPipeline = device.createRenderPipeline(pipelineDescriptor);

            // 7: Create GPUCommandEncoder to issue commands to the GPU
            // Note: render pass descriptor, command encoder, etc. are destroyed after use, fresh one needed for each frame.
            const commandEncoder = device.createCommandEncoder();

            // 8: Create GPURenderPassDescriptor to tell WebGPU which texture to draw into, then initiate render pass

            const renderPassDescriptor = {
                colorAttachments: [{
                    clearValue: clearColor,
                    loadOp: 'clear',
                    storeOp: 'store',
                    view: context.getCurrentTexture().createView()
                }]
            };

            const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);

            // 9: Draw the triangle

            passEncoder.setPipeline(renderPipeline);
            passEncoder.setVertexBuffer(0, vertexBuffer);
            passEncoder.draw(3);

            // End the render pass
            passEncoder.end();

            // 10: End frame by passing array of command buffers to command queue for execution
            device.queue.submit([commandEncoder.finish()]);
        }

        window.toDataURL = () => {
            const dataURL = canvas.toDataURL();
            window.open(dataURL, "_blank");
        }

        window.toBlob = () => {
            canvas.toBlob(blob => {
                const url = URL.createObjectURL(blob);
                window.open(url, "_blank");
            });
        }

        window.createBitmap = () => {
            createImageBitmap(canvas).then(bitmap => {
                console.log("ImageBitmap:", bitmap);
                alert("Bitmap created - check the console.");
            });
        }

        // Initial setup
        //updateCanvas();
    </script>
</body>

</html>